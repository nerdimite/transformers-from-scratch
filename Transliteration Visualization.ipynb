{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Transliteration Task\n",
    "### Training the transformers for transliteration on a small sample of hindi to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformer import Transformer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'रासविहारी': 'RASVIHARI', 'देवगन': 'DEVGAN', 'रोड': 'ROAD', 'शत्रुमर्दन': 'SHATRUMARDAN', 'महिजुबा': 'MAHIJUBA', 'सैबिन': 'SAIBIN', 'बिल': 'BILL', 'कॉस्बी': 'COSBY', 'रिश्ता': 'RISTA', 'कागज़': 'KAGAZ', 'का': 'KA', 'हातिम': 'HATIM', 'श्रीमयी': 'SRIMAYI', 'फरीहाह': 'FARIHAH', 'मैरीटाइम': 'MARITIME', 'म्युज़ियम': 'MUSIUM', 'ऑफ': 'OF', 'ग्रीस': 'GREECE', 'मंथन': 'MANTHAN', 'फ्रेंकोरशियन': 'FRANCORUSSIAN', 'वार': 'BAR', 'तन्मया': 'TANMYA', 'मल्ली': 'MALLI', 'केलीमुटु': 'KELIMUTU', 'मुटाटकर': 'MUTATAKAR', 'गंगा': 'GANGA', 'मैया': 'MAIYA', 'फरीदाह': 'FARIDAH', 'तहमीना': 'TAHMEENA', 'दुर्रानी': 'DURANII', 'डान्यूब': 'DANUBE', 'बलील': 'BALEEL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create english vocabulary\n",
    "english_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "eng_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "for index, alphabet in enumerate(english_alphabets) :\n",
    "    eng_vocab[alphabet] = index + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hindi vocabulary\n",
    "hin_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "for num in range(2304, 2436) :\n",
    "    hin_vocab[chr(num)] = num - 2301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into independent lists\n",
    "source, target = [], []\n",
    "for keys, values in dataset.items():\n",
    "    source.append(keys)\n",
    "    target.append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(sequence, vocab, max_len):\n",
    "    '''Encode a single sequence'''\n",
    "    encoded_seq = [vocab['<sos>']]\n",
    "    for char in sequence:\n",
    "        encoded_seq.append(vocab[char])\n",
    "    encoded_seq.append(vocab['<eos>'])\n",
    "\n",
    "    if len(encoded_seq) < max_len:\n",
    "        encoded_seq.extend([vocab['<pad>']] * (max_len - len(encoded_seq)))\n",
    "\n",
    "    return torch.LongTensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sequences, vocab):\n",
    "    '''Preprocesses a list of sequences'''\n",
    "    max_len = max([len(s) for s in sequences]) + 2\n",
    "\n",
    "    input_sequences = []\n",
    "    for seq in sequences:\n",
    "        input_sequences.append(encode_sequence(seq, vocab, max_len))\n",
    "    \n",
    "    return torch.stack(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode(source, hin_vocab).to(device)\n",
    "y = encode(target, eng_vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = 0\n",
    "src_vocab_size = len(hin_vocab)\n",
    "trg_vocab_size = len(eng_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embed = Transformer(src_vocab_size, trg_vocab_size,\n",
    "                    pad_idx, pad_idx, max_len=16, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_enc = Transformer(src_vocab_size, trg_vocab_size,\n",
    "                    pad_idx, pad_idx, max_len=16, device=device, pos_embed=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b20c0f36fc446ca747c0ca838e8cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_embed.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e05ac11822409b90aa194e21191c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_enc.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(sequence, vocab):\n",
    "    '''Decode integer encoding to text'''\n",
    "    rev_vocab = {v: k for k, v in vocab.items()}\n",
    "    decoded = ''\n",
    "    for i in sequence:\n",
    "        if i > 2:\n",
    "            decoded += rev_vocab[i]\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Input: रासविहारी\n",
      "Prediction: SARIHAH\n",
      "Ground Truth: RASVIHARI\n",
      "\n",
      "Input: रासविहारी\n",
      "Prediction: RASVIHARI\n",
      "Ground Truth: RASVIHARI\n",
      "\n",
      "==========\n",
      "Input: देवगन\n",
      "Prediction: DEVGAN\n",
      "Ground Truth: DEVGAN\n",
      "\n",
      "Input: देवगन\n",
      "Prediction: DEVGAN\n",
      "Ground Truth: DEVGAN\n",
      "\n",
      "==========\n",
      "Input: रोड\n",
      "Prediction: ROAD\n",
      "Ground Truth: ROAD\n",
      "\n",
      "Input: रोड\n",
      "Prediction: ROAD\n",
      "Ground Truth: ROAD\n",
      "\n",
      "==========\n",
      "Input: शत्रुमर्दन\n",
      "Prediction: SHATRUMARDAN\n",
      "Ground Truth: SHATRUMARDAN\n",
      "\n",
      "Input: शत्रुमर्दन\n",
      "Prediction: MANCORDAN\n",
      "Ground Truth: SHATRUMARDAN\n",
      "\n",
      "==========\n",
      "Input: महिजुबा\n",
      "Prediction: MAHIJUBA\n",
      "Ground Truth: MAHIJUBA\n",
      "\n",
      "Input: महिजुबा\n",
      "Prediction: MAHIJUBA\n",
      "Ground Truth: MAHIJUBA\n",
      "\n",
      "==========\n",
      "Input: सैबिन\n",
      "Prediction: SAIBIN\n",
      "Ground Truth: SAIBIN\n",
      "\n",
      "Input: सैबिन\n",
      "Prediction: SAIBIN\n",
      "Ground Truth: SAIBIN\n",
      "\n",
      "==========\n",
      "Input: बिल\n",
      "Prediction: BILL\n",
      "Ground Truth: BILL\n",
      "\n",
      "Input: बिल\n",
      "Prediction: BIL\n",
      "Ground Truth: BILL\n",
      "\n",
      "==========\n",
      "Input: कॉस्बी\n",
      "Prediction: COSBY\n",
      "Ground Truth: COSBY\n",
      "\n",
      "Input: कॉस्बी\n",
      "Prediction: COSBY\n",
      "Ground Truth: COSBY\n",
      "\n",
      "==========\n",
      "Input: रिश्ता\n",
      "Prediction: SRIMATI\n",
      "Ground Truth: RISTA\n",
      "\n",
      "Input: रिश्ता\n",
      "Prediction: RISTA\n",
      "Ground Truth: RISTA\n",
      "\n",
      "==========\n",
      "Input: कागज़\n",
      "Prediction: KAGAZ\n",
      "Ground Truth: KAGAZ\n",
      "\n",
      "Input: कागज़\n",
      "Prediction: KAGAZ\n",
      "Ground Truth: KAGAZ\n",
      "\n",
      "==========\n",
      "Input: का\n",
      "Prediction: KA\n",
      "Ground Truth: KA\n",
      "\n",
      "Input: का\n",
      "Prediction: KA\n",
      "Ground Truth: KA\n",
      "\n",
      "==========\n",
      "Input: हातिम\n",
      "Prediction: HATIM\n",
      "Ground Truth: HATIM\n",
      "\n",
      "Input: हातिम\n",
      "Prediction: HATIM\n",
      "Ground Truth: HATIM\n",
      "\n",
      "==========\n",
      "Input: श्रीमयी\n",
      "Prediction: SRIMAYI\n",
      "Ground Truth: SRIMAYI\n",
      "\n",
      "Input: श्रीमयी\n",
      "Prediction: SRIMAYI\n",
      "Ground Truth: SRIMAYI\n",
      "\n",
      "==========\n",
      "Input: फरीहाह\n",
      "Prediction: FARIHAH\n",
      "Ground Truth: FARIHAH\n",
      "\n",
      "Input: फरीहाह\n",
      "Prediction: FARIHAH\n",
      "Ground Truth: FARIHAH\n",
      "\n",
      "==========\n",
      "Input: मैरीटाइम\n",
      "Prediction: MARITIME\n",
      "Ground Truth: MARITIME\n",
      "\n",
      "Input: मैरीटाइम\n",
      "Prediction: MARITIME\n",
      "Ground Truth: MARITIME\n",
      "\n",
      "==========\n",
      "Input: म्युज़ियम\n",
      "Prediction: MUSIUM\n",
      "Ground Truth: MUSIUM\n",
      "\n",
      "Input: म्युज़ियम\n",
      "Prediction: MUSIUM\n",
      "Ground Truth: MUSIUM\n",
      "\n",
      "==========\n",
      "Input: ऑफ\n",
      "Prediction: OF\n",
      "Ground Truth: OF\n",
      "\n",
      "Input: ऑफ\n",
      "Prediction: OF\n",
      "Ground Truth: OF\n",
      "\n",
      "==========\n",
      "Input: ग्रीस\n",
      "Prediction: GREECE\n",
      "Ground Truth: GREECE\n",
      "\n",
      "Input: ग्रीस\n",
      "Prediction: GREEECE\n",
      "Ground Truth: GREECE\n",
      "\n",
      "==========\n",
      "Input: मंथन\n",
      "Prediction: MANTHAN\n",
      "Ground Truth: MANTHAN\n",
      "\n",
      "Input: मंथन\n",
      "Prediction: MANTHAN\n",
      "Ground Truth: MANTHAN\n",
      "\n",
      "==========\n",
      "Input: फ्रेंकोरशियन\n",
      "Prediction: FRANCORUSSIAN\n",
      "Ground Truth: FRANCORUSSIAN\n",
      "\n",
      "Input: फ्रेंकोरशियन\n",
      "Prediction: FRANCORUSIAN\n",
      "Ground Truth: FRANCORUSSIAN\n",
      "\n",
      "==========\n",
      "Input: वार\n",
      "Prediction: BAR\n",
      "Ground Truth: BAR\n",
      "\n",
      "Input: वार\n",
      "Prediction: BAR\n",
      "Ground Truth: BAR\n",
      "\n",
      "==========\n",
      "Input: तन्मया\n",
      "Prediction: TANMYA\n",
      "Ground Truth: TANMYA\n",
      "\n",
      "Input: तन्मया\n",
      "Prediction: TANMYA\n",
      "Ground Truth: TANMYA\n",
      "\n",
      "==========\n",
      "Input: मल्ली\n",
      "Prediction: MALLI\n",
      "Ground Truth: MALLI\n",
      "\n",
      "Input: मल्ली\n",
      "Prediction: MALI\n",
      "Ground Truth: MALLI\n",
      "\n",
      "==========\n",
      "Input: केलीमुटु\n",
      "Prediction: KELIMUTU\n",
      "Ground Truth: KELIMUTU\n",
      "\n",
      "Input: केलीमुटु\n",
      "Prediction: KELIMUTU\n",
      "Ground Truth: KELIMUTU\n",
      "\n",
      "==========\n",
      "Input: मुटाटकर\n",
      "Prediction: MUTATAKAR\n",
      "Ground Truth: MUTATAKAR\n",
      "\n",
      "Input: मुटाटकर\n",
      "Prediction: MUTAKAKAR\n",
      "Ground Truth: MUTATAKAR\n",
      "\n",
      "==========\n",
      "Input: गंगा\n",
      "Prediction: GANGA\n",
      "Ground Truth: GANGA\n",
      "\n",
      "Input: गंगा\n",
      "Prediction: GANGA\n",
      "Ground Truth: GANGA\n",
      "\n",
      "==========\n",
      "Input: मैया\n",
      "Prediction: MAIYA\n",
      "Ground Truth: MAIYA\n",
      "\n",
      "Input: मैया\n",
      "Prediction: MAIYA\n",
      "Ground Truth: MAIYA\n",
      "\n",
      "==========\n",
      "Input: फरीदाह\n",
      "Prediction: FARIDAH\n",
      "Ground Truth: FARIDAH\n",
      "\n",
      "Input: फरीदाह\n",
      "Prediction: FARIDAH\n",
      "Ground Truth: FARIDAH\n",
      "\n",
      "==========\n",
      "Input: तहमीना\n",
      "Prediction: TAHMEENA\n",
      "Ground Truth: TAHMEENA\n",
      "\n",
      "Input: तहमीना\n",
      "Prediction: TAHMEEEENA\n",
      "Ground Truth: TAHMEENA\n",
      "\n",
      "==========\n",
      "Input: दुर्रानी\n",
      "Prediction: DURANII\n",
      "Ground Truth: DURANII\n",
      "\n",
      "Input: दुर्रानी\n",
      "Prediction: DURANII\n",
      "Ground Truth: DURANII\n",
      "\n",
      "==========\n",
      "Input: डान्यूब\n",
      "Prediction: DEVGAN\n",
      "Ground Truth: DANUBE\n",
      "\n",
      "Input: डान्यूब\n",
      "Prediction: DANUBE\n",
      "Ground Truth: DANUBE\n",
      "\n",
      "==========\n",
      "Input: बलील\n",
      "Prediction: BALEEL\n",
      "Ground Truth: BALEEL\n",
      "\n",
      "Input: बलील\n",
      "Prediction: BALEEEEL\n",
      "Ground Truth: BALEEL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 32):\n",
    "    testX = encode_sequence(list(dataset.items())[i][0], hin_vocab, max_len=16).unsqueeze(0).to(device)\n",
    "    testY = encode_sequence(list(dataset.items())[i][1], eng_vocab, max_len=16).tolist()\n",
    "\n",
    "    print('=' * 10)\n",
    "    preds = model_embed.predict(testX, device)\n",
    "    print(\"Input:\", decode_sequence(testX.squeeze(0).tolist(), hin_vocab))\n",
    "    print(\"Prediction:\", decode_sequence(preds, eng_vocab))\n",
    "    print(\"Ground Truth:\", decode_sequence(testY, eng_vocab))\n",
    "\n",
    "    print()\n",
    "\n",
    "    preds = model_enc.predict(testX, device)\n",
    "    print(\"Input:\", decode_sequence(testX.squeeze(0).tolist(), hin_vocab))\n",
    "    print(\"Prediction:\", decode_sequence(preds, eng_vocab))\n",
    "    print(\"Ground Truth:\", decode_sequence(testY, eng_vocab))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/eng5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_embedding(model.encoder.word_embedding.weight,\n",
    "#                      metadata = hin_vocab.keys(),\n",
    "#                      tag = f'word embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_embedding(model.encoder.positional_embedding.weight,\n",
    "#                      metadata = np.arange(model.encoder.positional_embedding.weight.shape[0]),\n",
    "#                      tag = f'position embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAA with positional embeddings\n",
    "A_pos = [model_embed.decoder.word_embedding.weight[24] + model_embed.decoder.positional_embedding.weight[i] for i in range(16)]\n",
    "\n",
    "# AAA with 1/16, 2/16, 3/16\n",
    "A_val = [model_enc.decoder.word_embedding.weight[24] + (i+1 / 16) for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(torch.stack(A_pos + A_val),\n",
    "                     metadata = [f'A_pos_{i+1}' for i in range(16)] + [f'A_val_{i+1}' for i in range(16)],\n",
    "                     tag = f'Positional Embed vs Value_Labelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(torch.stack(A_pos + A_val),\n",
    "                     metadata = [f'A_pos' for i in range(16)] + [f'A_val' for i in range(16)],\n",
    "                     tag = f'Positional Embed vs Value_Color Coded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0\n",
      "Mean tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(-3.0886, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(2.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 1\n",
      "Mean tensor(1.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(-2.0886, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(3.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 2\n",
      "Mean tensor(2.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(-1.0886, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(4.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 3\n",
      "Mean tensor(3.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(-0.0886, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(5.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 4\n",
      "Mean tensor(4.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(0.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(6.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 5\n",
      "Mean tensor(5.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(1.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(7.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 6\n",
      "Mean tensor(6.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(2.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(8.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 7\n",
      "Mean tensor(7.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(3.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(9.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 8\n",
      "Mean tensor(8.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(4.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(10.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 9\n",
      "Mean tensor(9.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(5.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(11.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 10\n",
      "Mean tensor(10.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(6.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(12.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 11\n",
      "Mean tensor(11.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(7.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(13.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 12\n",
      "Mean tensor(12.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(8.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(14.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 13\n",
      "Mean tensor(13.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(9.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(15.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 14\n",
      "Mean tensor(14.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(10.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(16.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "\n",
      " 15\n",
      "Mean tensor(15.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Std tensor(0.9525, device='cuda:0', grad_fn=<StdBackward>)\n",
      "Min tensor(11.9114, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "Max tensor(17.3729, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    print('\\n', i)\n",
    "    print('Mean', A_val[i].mean())\n",
    "    print('Std', A_val[i].std())\n",
    "    print('Min', A_val[i].min())\n",
    "    print('Max', A_val[i].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60fbf1aecf0122793952a73a80d27bc8732eff9e143c13520ca117508929b1c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
