{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Transliteration Task\n",
    "### Training the transformers for transliteration on a small sample of hindi to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {'रासविहारी': 'RASVIHARI', 'देवगन': 'DEVGAN', 'रोड': 'ROAD', 'शत्रुमर्दन': 'SHATRUMARDAN', 'महिजुबा': 'MAHIJUBA', 'सैबिन': 'SAIBIN', 'बिल': 'BILL', 'कॉस्बी': 'COSBY', 'रिश्ता': 'RISTA', 'कागज़': 'KAGAZ', 'का': 'KA', 'हातिम': 'HATIM', 'श्रीमयी': 'SRIMAYI', 'फरीहाह': 'FARIHAH', 'मैरीटाइम': 'MARITIME', 'म्युज़ियम': 'MUSIUM', 'ऑफ': 'OF', 'ग्रीस': 'GREECE', 'मंथन': 'MANTHAN', 'फ्रेंकोरशियन': 'FRANCORUSSIAN', 'वार': 'BAR', 'तन्मया': 'TANMYA', 'मल्ली': 'MALLI', 'केलीमुटु': 'KELIMUTU', 'मुटाटकर': 'MUTATAKAR', 'गंगा': 'GANGA', 'मैया': 'MAIYA', 'फरीदाह': 'FARIDAH', 'तहमीना': 'TAHMEENA', 'दुर्रानी': 'DURANII', 'डान्यूब': 'DANUBE', 'बलील': 'BALEEL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create english vocabulary\n",
    "english_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "eng_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "for index, alphabet in enumerate(english_alphabets) :\n",
    "    eng_vocab[alphabet] = index + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hindi vocabulary\n",
    "hin_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
    "for num in range(2304, 2436) :\n",
    "    hin_vocab[chr(num)] = num - 2301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into independent lists\n",
    "source, target = [], []\n",
    "for keys, values in dataset.items():\n",
    "    source.append(keys)\n",
    "    target.append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence(sequence, vocab, max_len):\n",
    "    '''Encode a single sequence'''\n",
    "    encoded_seq = [vocab['<sos>']]\n",
    "    for char in sequence:\n",
    "        encoded_seq.append(vocab[char])\n",
    "    encoded_seq.append(vocab['<eos>'])\n",
    "\n",
    "    if len(encoded_seq) < max_len:\n",
    "        encoded_seq.extend([vocab['<pad>']] * (max_len - len(encoded_seq)))\n",
    "\n",
    "    return torch.LongTensor(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sequences, vocab):\n",
    "    '''Preprocesses a list of sequences'''\n",
    "    max_len = max([len(s) for s in sequences]) + 2\n",
    "\n",
    "    input_sequences = []\n",
    "    for seq in sequences:\n",
    "        input_sequences.append(encode_sequence(seq, vocab, max_len))\n",
    "    \n",
    "    return torch.stack(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode(source, hin_vocab).to(device)\n",
    "y = encode(target, eng_vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = 0\n",
    "src_vocab_size = len(hin_vocab)\n",
    "trg_vocab_size = len(eng_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(src_vocab_size, trg_vocab_size,\n",
    "                    pad_idx, pad_idx, device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ea403bf7cc4cad97aea3f18198981f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(total=epochs)\n",
    "for i in range(epochs):\n",
    "\n",
    "    # shift the target to the left so it predicts the last token\n",
    "    out = model(X, y[:, :-1])\n",
    "    out = out.reshape(-1, out.shape[2])\n",
    "    # print('Output:', out.shape)\n",
    "\n",
    "    target = y[:, 1:].reshape(-1)  # shift the labels to the right\n",
    "    # print('Target:', target.shape)\n",
    "\n",
    "    loss = criterion(out, target)\n",
    "    # print(f\"Loss {loss.item()}\")\n",
    "    loss.backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "    optimizer.step()\n",
    "\n",
    "    pbar.set_postfix({'Loss': loss.item()})\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(sequence, vocab):\n",
    "    '''Decode integer encoding to text'''\n",
    "    rev_vocab = {v: k for k, v in vocab.items()}\n",
    "    decoded = ''\n",
    "    for i in sequence:\n",
    "        if i > 2:\n",
    "            decoded += rev_vocab[i]\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(source):\n",
    "    preds = [1]  # Intialize predictions with SOS\n",
    "    max_gen_len = 15\n",
    "\n",
    "    for i in range(max_gen_len):\n",
    "\n",
    "        input_tensor = torch.tensor(preds).unsqueeze(0).to(device)\n",
    "        # print('Input Tensor:', input_tensor)\n",
    "\n",
    "        # Predict targets\n",
    "        with torch.no_grad():\n",
    "            out = model(source, input_tensor)\n",
    "            # print('Raw Output Shape:', out.shape)\n",
    "\n",
    "        # Get the last word with highest probability\n",
    "        word_idx = out.argmax(dim=-1)[:, -1].item()\n",
    "        # print('Next Word Index:', word_idx)\n",
    "\n",
    "        # Append to outputs\n",
    "        preds.append(word_idx)\n",
    "\n",
    "        if word_idx == 2:  # If token is EOS then stop predicting\n",
    "            break\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "testX = X[idx].unsqueeze(0).to(device)\n",
    "testY = y[idx].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: रिश्ता\n",
      "Prediction: RISTA\n",
      "Ground Truth: RISTA\n"
     ]
    }
   ],
   "source": [
    "preds = predict(testX)\n",
    "print(\"Input:\", decode_sequence(testX.squeeze(0).tolist(), hin_vocab))\n",
    "print(\"Prediction:\", decode_sequence(preds, eng_vocab))\n",
    "print(\"Ground Truth:\", decode_sequence(testY, eng_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60fbf1aecf0122793952a73a80d27bc8732eff9e143c13520ca117508929b1c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
